{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Com relação a um projeto de Ciência de Dados, assinale a alternativa correta.  \n",
    "Questão 1 Resposta  \n",
    "**a.A separação dos conjuntos de teste e treinamento é feita após a limpeza dos dados.**  \n",
    "b.Se há dados faltantes, podemos usar o conjunto de teste para ajustá-los usando um modelo de regressão.   \n",
    "c.A seleção dos atributos nunca melhora o valor da acurácia na classificação.  \n",
    "d.A regressão é feita antes da seleção dos conjuntos de treinamento e teste.  \n",
    "e.A análise exploratória é feita antes da limpeza dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Com relação a um projeto de Ciência de Dados, assinale a alternativa incorreta.  \n",
    "Questão 2 Resposta  \n",
    "**a.A seleção de atributos é feita no conjunto de teste.**   \n",
    "b.A validação cruzada é usada na seleção do modelo.  \n",
    "c.A seleção de atributos permite simplificar o modelo.  \n",
    "d.A avaliação do modelo é feita no conjunto de teste.  \n",
    "e.Estatística descritiva ajuda a entender os dados e a relação entre os atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Assinale a sequência correta dos passos em um projeto de Ciência de Dados:  \n",
    "Questão 3 Resposta  \n",
    "**a.1 – Limpeza dos dados, 2 - Estatística descritiva, 3 - Aprendizado supervisionado**  \n",
    "b.1 - Avaliação do modelo. 2- Estatística descritiva. 3- Análise exploratória.  \n",
    "c.1 - Análise exploratória. 2- Limpeza. 3 – Transformação dos dados.  \n",
    "d.1 - Validação cruzada. 2 – Limpeza. 3 - Regressão.  \n",
    "e.1 - Análise exploratória. 2 – Classificação. 3 – Limpeza dos dados  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Considere a base de dados da Vehicle.  Usando o algoritmo random forest, qual é o atributo mais importante para a classificação? Considere o código abaixo para ler e preparar os dados.  \n",
    "\n",
    "```python\n",
    "import random\n",
    "random.seed(42)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('data/Vehicle.csv', header=(0))\n",
    "\n",
    "# remove NaN\n",
    "data = data.dropna(axis='rows') #\n",
    "# armazena o nome das classes\n",
    "classes = np.array(pd.unique(data[data.columns[-1]]), dtype=str)  #name of the clases\n",
    "features_names = data.columns\n",
    "\n",
    "data = data.to_numpy()\n",
    "nrow,ncol = data.shape\n",
    "y = data[:,-1]\n",
    "X = data[:,0:ncol-1]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "p = 0.2 # fracao de elementos no conjunto de teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = p, random_state = 42)\n",
    "```\n",
    "Questão 4 Resposta  \n",
    "**a.Max.L.Ra**  \n",
    "b.Comp  \n",
    "c.Scat.Ra\n",
    "d.D.Circ  \n",
    "e.Max.L.Rect  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('data/Vehicle.csv', header=(0))\n",
    "\n",
    "# remove NaN\n",
    "data = data.dropna(axis='rows') #\n",
    "# armazena o nome das classes\n",
    "classes = np.array(pd.unique(data[data.columns[-1]]), dtype=str)  #name of the clases\n",
    "features_names = data.columns\n",
    "\n",
    "data = data.to_numpy()\n",
    "nrow,ncol = data.shape\n",
    "y = data[:,-1]\n",
    "X = data[:,0:ncol-1]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "p = 0.2 # fracao de elementos no conjunto de teste\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = p, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "model = rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Comp', 'Circ', 'D.Circ', 'Rad.Ra', 'Pr.Axis.Ra', 'Max.L.Ra', 'Scat.Ra',\n",
       "       'Elong', 'Pr.Axis.Rect', 'Max.L.Rect', 'Sc.Var.Maxis', 'Sc.Var.maxis',\n",
       "       'Ra.Gyr', 'Skew.Maxis', 'Skew.maxis', 'Kurt.maxis', 'Kurt.Maxis',\n",
       "       'Holl.Ra', 'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Comp', 'Circ', 'D.Circ', 'Rad.Ra', 'Pr.Axis.Ra', 'Max.L.Ra', 'Scat.Ra',\n",
       "       'Elong', 'Pr.Axis.Rect', 'Max.L.Rect', 'Sc.Var.Maxis', 'Sc.Var.maxis',\n",
       "       'Ra.Gyr', 'Skew.Maxis', 'Skew.maxis', 'Kurt.maxis', 'Kurt.Maxis',\n",
       "       'Holl.Ra'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_names[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature 0',\n",
       " 'feature 1',\n",
       " 'feature 2',\n",
       " 'feature 3',\n",
       " 'feature 4',\n",
       " 'feature 5',\n",
       " 'feature 6',\n",
       " 'feature 7',\n",
       " 'feature 8',\n",
       " 'feature 9',\n",
       " 'feature 10',\n",
       " 'feature 11',\n",
       " 'feature 12',\n",
       " 'feature 13',\n",
       " 'feature 14',\n",
       " 'feature 15',\n",
       " 'feature 16',\n",
       " 'feature 17']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"feature {i}\" for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Max.L.Ra        0.102073\n",
       "Sc.Var.maxis    0.086515\n",
       "Max.L.Rect      0.082252\n",
       "D.Circ          0.071266\n",
       "Elong           0.064364\n",
       "Scat.Ra         0.064318\n",
       "Pr.Axis.Ra      0.058202\n",
       "Sc.Var.Maxis    0.056247\n",
       "Comp            0.053172\n",
       "Holl.Ra         0.050468\n",
       "Skew.Maxis      0.045435\n",
       "Circ            0.042660\n",
       "Kurt.Maxis      0.040188\n",
       "Kurt.maxis      0.039978\n",
       "Rad.Ra          0.039785\n",
       "Ra.Gyr          0.038534\n",
       "Skew.maxis      0.038075\n",
       "Pr.Axis.Rect    0.026468\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "importances = rf.feature_importances_\n",
    "features_names\n",
    "\n",
    "forest_importances = pd.Series(importances, index=features_names[:-1])\n",
    "forest_importances.sort_values(ascending=False)\n",
    "# fig, ax = plt.subplots()\n",
    "# forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "# ax.set_title(\"Feature importances using MDI\")\n",
    "# ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "start_time = time.time()\n",
    "result = permutation_importance(\n",
    "    forest, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "\n",
    "forest_importances = pd.Series(result.importances_mean, index=feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mba_data_science",
   "language": "python",
   "name": "mba_data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
