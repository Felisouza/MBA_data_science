{"cells":[{"cell_type":"markdown","metadata":{"id":"fz9XLztTjsxq"},"source":["# MBA em Ciência de Dados\n","## Técnicas Avançadas de Captura e Tratamento de Dados\n","\n","\n","### <span style=\"color:darkred\">Dados não estruturados: sinais e imagens</span>\n","\n","### <span style=\"color:darkred\">Avaliação</span>\n","\n","Moacir Antonelli Ponti\n","\n","CeMEAI - ICMC/USP São Carlos\n","\n","---\n","\n","#### <span style=\"color:red\">As respostas devem ser dadas no Moodle, o notebook deve ser usado para executar código para obtenção dos resultados.</span>\n","\n","---"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"Czxie0uxjsxs"},"outputs":[],"source":["# carregando as bibliotecas necessárias\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"KnB_WG7ljsxv"},"source":["### Questão 1)\n","\n","Escolha a alternativa que descreva dados estruturados:\n","\n","(a) valores obtidos de um sensor de aceleração de um celular a uma taxa de 100 Hz<br>\n","(b) texto obtido a partir da execução de optical character recognition de um documento PDF<br>\n","(c) uma imagem da face de uma pessoa armazenada numa base de dados de uma empresa e usada para verificação biométrica<br>\n","**(d) maior e menor preços referente ao ID de um produto, obtidos de uma base de dados histórica de um e-commerce**<br>\n","(e) array de pixels de uma imagem obtida da folha de uma planta em um cultivo agrícola por uma câmera digital<br>\n"]},{"cell_type":"markdown","metadata":{"id":"pV8VlbCwjsxt"},"source":["### Questão 2)\n","\n","É um exemplo de dado não estruturado do tipo sequencial e temporal:\n","\n","(a) os valores de quilômetros de congestionamento estimados em cada bairro da cidade de São Paulo em mesma hora e minuto de um dia<br>\n","(b) os valores de temperatura coletados num mesmo momento em todas as cidades do estado de São Paulo, ordenadas da maior para a menor<br>\n","(c) a coluna idade de uma tabela de um banco de dados, ordenada de forma ascendente<br>\n","(d) os valores de todos os preços de um produto ao longo de um ano obtidos de uma base de dados histórica, ordenados cronologicamente<br>\n","**(e) o áudio relativo à voz de uma pessoa gravado por celular**<br>"]},{"cell_type":"markdown","metadata":{"id":"3Z4gbw3ojsx0"},"source":["### Questão 3)\n","\n","Considere as seguintes afirmações sobre o processo de obtenção de embeddings de imagens extraídos de uma base de dados alvo por meio do uso de modelos de redes neurais pré-treinados em um dataset de origem (e diferente do dataset alvo):\n","\n","I - são obtidos aplicando transformações como a Transformada de Fourier ou Análise de Componentes Principais na base de imagens alvo<br>\n","II - são características extraídas obtendo a saída da camada de classificação de uma rede neural pré-treinada<br>\n","III - são características extraídas obtendo a saída de uma camada interna/intermediária de uma rede neural pré-treinada<br>\n","IV - esse processo assume que o modelo pré-treinado utilizado generaliza para outras tarefas para além do dataset de origem<br>\n","V - os embeddings resultantes podem ser usado como entrada em algoritmos de aprendizado supervisionado como regressores e classificadores<br>\n","\n","São verdadeiras as afirmações:\n","\n","(a) I e II<br>\n","**(b) II e IV**<br>\n","(b) II, III e IV<br>\n","(c) III e IV<br>\n","**(e) III, IV e V**<br>"]},{"cell_type":"markdown","metadata":{"id":"DovWzEtBjsx1"},"source":["### Questão 4)\n","\n","Carregue os dados do arquivo `pollution_2024.csv` utilizando o comando `pd.read_csv()`\n","\n","Esse dataframe possui 6 colunas (A, B, C, D, E, F) relativas à medição de monóxido de carbono em 6 localizações. Foram feitas medições durante 2 dias a cada 5 minutos em diferentes posições de uma cidade.\n","\n","Queremos identificar qual das localizações entre: B, C, D, E, F mais se assemelha à A. Para isso, extraia um vetor de características (para cada sinal) composto de 5 valores:\n","* Entropia da energia (calculada com 6 blocos)\n","* Entropia da energia (calculada com 12 blocos)\n","* Entropia espectral (calculada com 6 blocos)\n","* Entropia espectral (calculada com 12 blocos)\n","* Dispersão espectral (considere frequência = 0.5Hz)\n","\n","Compute a distância Euclidiana entre os vetores de características computados e identifique qual sinal (B, C, D, E ou F) é mais próximo de A.\n","\n","(a) sinal B<br>\n","(b) sinal C<br>\n","(c) sinal D<br>\n","(d) sinal E<br>\n","**(e) sinal F**<br>"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"AwZHA66Mjsx2","scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>carbon_monoxide_A</th>\n","      <th>carbon_monoxide_B</th>\n","      <th>carbon_monoxide_C</th>\n","      <th>carbon_monoxide_D</th>\n","      <th>carbon_monoxide_E</th>\n","      <th>carbon_monoxide_F</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>49</td>\n","      <td>78</td>\n","      <td>57</td>\n","      <td>57</td>\n","      <td>123</td>\n","      <td>34</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>45</td>\n","      <td>81</td>\n","      <td>54</td>\n","      <td>54</td>\n","      <td>124</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>48</td>\n","      <td>86</td>\n","      <td>59</td>\n","      <td>59</td>\n","      <td>126</td>\n","      <td>27</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   carbon_monoxide_A  carbon_monoxide_B  carbon_monoxide_C  carbon_monoxide_D  \\\n","0                 49                 78                 57                 57   \n","1                 45                 81                 54                 54   \n","2                 48                 86                 59                 59   \n","\n","   carbon_monoxide_E  carbon_monoxide_F  \n","0                123                 34  \n","1                124                 32  \n","2                126                 27  "]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","data = pd.read_csv('./dados/pollution_2024.csv',)\n","data.head(3)"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"3-PKJjbAjsx4"},"outputs":[],"source":["def entropia_energia(sinal, n_blocos=10):\n","    '''Entropia da energia do sinal'''\n","    # energia total\n","    energia_sinal = np.sum(sinal ** 2)\n","    M = len(sinal)\n","\n","    # calcula janelas dentro do sinal\n","    M_janelas = int(np.floor(M / n_blocos))\n","    # verifica se tamanho dos blocos\n","    # é multiplo do tamanho do sinal\n","    if M != M_janelas * n_blocos:\n","        sinal = sinal[0:M_janelas * n_blocos]\n","\n","    # monta matriz [M_janelas x n_blocos]\n","    janelas = sinal.reshape(M_janelas, n_blocos, order='F').copy()\n","\n","    # Computa energias de cada janela (normalizada pela do sinal)\n","    e_janelas = np.sum(janelas ** 2, axis=0) / (energia_sinal + 0.0001)\n","    #print(e_janelas)\n","\n","    # Computa entropia entre energias das janelas\n","    entropia = -np.sum(e_janelas * np.log2(e_janelas + 0.0001))\n","    return entropia\n","\n","def entropia_espectral(sinal, n_blocos=16):\n","    \"\"\"Computes the spectral entropy\"\"\"\n","\n","    fft_abs = np.abs(np.fft.fft(sinal))\n","\n","    entropia_esp = entropia_energia(fft_abs, n_blocos=n_blocos)\n","\n","    return entropia_esp\n","\n","def centroide_dispersao_espectral(sinal, tx_amostragem):\n","    '''Calcula o centro de massa e dispersão do espectro do sinal'''\n","\n","    fft_abs = np.abs( np.fft.fft(sinal) )\n","    N = len(fft_abs)\n","\n","    # indices de frequencia\n","    ind = (np.arange(1, N+1)) * (tx_amostragem / (2.0*N))\n","\n","    # calcula a distribuicao do espectro normalizando para soma unitária\n","    Xt = fft_abs.copy()\n","    Xt = Xt / Xt.max()\n","    NUM = np.sum(ind * Xt)\n","    DEN = np.sum(Xt) + 0.0001\n","\n","    # Centroide:\n","    centroide = (NUM / DEN)\n","\n","    # Dispersão:\n","    dispersao = np.sqrt(np.sum(((ind - centroide) ** 2) * Xt) / DEN)\n","\n","    # Normalizacao do centroide\n","    centroide = centroide / (tx_amostragem / 2.0)\n","\n","    # Normalizando:\n","    dispersao = dispersao / (tx_amostragem / 2.0)\n","\n","    return centroide, dispersao"]},{"cell_type":"markdown","metadata":{"id":"n7G8eC0MxW9f"},"source":["### Questão 5)\n","\n","Carregue o modelo pré-treinado base MobileNetV2 conforme visto em aula e instruções em: [https://keras.io/api/applications/mobilenet/#mobilenetv2-function]. Use o código disponível no notebook, completando com o código necessário para obter as características de 4 imagens utilizando o modelo de rede neural. Esse modelo deve ter as seguintes camadas: entrada, camada de pré-processamento da MobileNetV2, modelo base MobileNetV2 e camada GlobalAveragePooling2D. Ao carregar o modelo, utilize os parâmetros `include_top=False`, `weights='imagenet'` e o `input_shape` adequado para as imagens que foram carregadas.\n","\n","Siga os seguintes passos:\n","\n","1. Obtenha os embeddings a partir do modelo pré-treinado, garantindo que sejam vetores unidimensionais para cada imagem (use reshape se necessário), para obter vetores de características para as imagens;\n","2. Compute a distância Euclidiana entre o embedding da imagem 0 (primeira imagem carregada) e os embeddings das outras imagens (imagens 1, 2 e 3);\n","3. Ordene as imagens 1, 2 e 3 da mais próxima para a mais distante da imagem 0, segundo a distância computada no passo anterior.\n","\n","Qual foi a ordem obtida?\n","\n","(a) 1, 2, 3 <br>\n","(b) 1, 3, 2 <br>\n","(c) 2, 1, 3 <br>\n","**(d) 2, 3, 1**<br>\n","(e) 3, 1, 2 <br>"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"gQshrD8jyPXt"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import imageio.v2 as imageio\n","\n","img0 = imageio.imread(\"dados/texture_dotted.jpg\")\n","img1 = imageio.imread(\"dados/texture_dotted2.jpg\")\n","img2 = imageio.imread(\"dados/texture_dotted3.jpg\")\n","img3 = imageio.imread(\"dados/texture_chequered.jpg\")\n","dataset = np.stack([img0, img1, img2, img3])\n"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"data":{"text/plain":["array([[[188,  26,  37],\n","        [210, 117, 135],\n","        [238, 179, 183],\n","        ...,\n","        [189,  51,  66],\n","        [195,  72,  90],\n","        [195,  74,  89]],\n","\n","       [[190,  31,  49],\n","        [215, 141, 154],\n","        [230, 174, 173],\n","        ...,\n","        [246, 164, 170],\n","        [245, 158, 164],\n","        [235, 160, 157]],\n","\n","       [[189,  86, 103],\n","        [230, 174, 177],\n","        [217, 136, 133],\n","        ...,\n","        [195,  86,  89],\n","        [196,  47,  51],\n","        [193,  43,  44]],\n","\n","       ...,\n","\n","       [[ 52,  35,  28],\n","        [ 51,  32,  26],\n","        [ 51,  34,  27],\n","        ...,\n","        [ 58,  38,  29],\n","        [ 58,  35,  27],\n","        [ 60,  37,  29]],\n","\n","       [[ 52,  38,  29],\n","        [ 52,  33,  26],\n","        [ 54,  35,  28],\n","        ...,\n","        [ 98,  85,  76],\n","        [121, 111, 101],\n","        [121, 108,  99]],\n","\n","       [[147, 137, 128],\n","        [133, 121, 109],\n","        [ 87,  73,  60],\n","        ...,\n","        [198, 193, 187],\n","        [193, 194, 188],\n","        [192, 191, 189]]], dtype=uint8)"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["dataset[0]"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"tUxoge6jZe5I"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\feh_s\\AppData\\Local\\Temp\\ipykernel_30864\\1561958560.py:1: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","  base_model = tf.keras.applications.MobileNetV2(\n"]}],"source":["base_model = tf.keras.applications.MobileNetV2(\n","    input_shape=(150, 150, 3),\n","    include_top=False,\n","    weights=\"imagenet\"\n",")\n"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["# desde a entrada (formato da imagem) até as features de saída\n","inputs = tf.keras.Input(shape=(150, 150, 3))\n","x = tf.keras.applications.mobilenet.preprocess_input(inputs)\n","x = base_model(x)\n","features = tf.keras.layers.GlobalAveragePooling2D()(x)\n","\n","# modelo\n","model_extract_features = tf.keras.Model(inputs, features)\n"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"]}],"source":["features = model_extract_features.predict(dataset)"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.13760695, 1.9129977 , 0.        , ..., 0.18433817, 1.9960895 ,\n","        0.        ],\n","       [0.01284895, 0.02950228, 0.        , ..., 1.1854535 , 0.03305384,\n","        0.        ],\n","       [0.        , 2.5381374 , 0.        , ..., 3.0048265 , 1.3200557 ,\n","        0.5475383 ],\n","       [0.        , 1.5047385 , 0.        , ..., 0.09732315, 0.05222915,\n","        0.        ]], dtype=float32)"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["\n","features"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.13760695, 1.9129977 , 0.        , ..., 0.18433817, 1.9960895 ,\n","        0.        ],\n","       [0.01284895, 0.02950228, 0.        , ..., 1.1854535 , 0.03305384,\n","        0.        ],\n","       [0.        , 2.5381374 , 0.        , ..., 3.0048265 , 1.3200557 ,\n","        0.5475383 ],\n","       [0.        , 1.5047385 , 0.        , ..., 0.09732315, 0.05222915,\n","        0.        ]], dtype=float32)"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["features = features.reshape(len(features), -1)\n","features"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[],"source":["def distancia(array1, array2):\n","    distancia_euclidiana = np.linalg.norm(array1 - array2)\n","    return distancia_euclidiana\n"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Distancia 0 com 1: 37.184383392333984\n"," Distancia 0 com 2: 29.647626876831055\n"," Distancia 0 com 3: 33.88526153564453\n","\n"]}],"source":["print(\n","    f\"Distancia 0 com 1: {distancia(features[0], features[1])}\\n\",\n","    f\"Distancia 0 com 2: {distancia(features[0], features[2])}\\n\",\n","    f\"Distancia 0 com 3: {distancia(features[0], features[3])}\\n\"\n","    )"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"mba_data_science","language":"python","name":"mba_data_science"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
