{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\"> MBA em Ciência de Dados</font>\n",
    "# <font color=\"blue\">Técnicas Avançadas para Captura e Tratamento de Dados</font>\n",
    "\n",
    "## <font color=\"blue\"> Matriz Documento $\\times$ Palavras - Bag of Words</font>\n",
    "    \n",
    "## <font color=\"blue\">Avaliação Solução</font>\n",
    "\n",
    "**Material Produzido por Luis Gustavo Nonato**<br>\n",
    "**Cemeai - ICMC/USP São Carlos**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os exercícios abaixo fazem uso da coleção de documentos presente no diretório `DocCol2` contido no arquivo <font style=\"font-family: monaco\"> DocCol.zip</font>, o qual pode ser baixado do Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1)\n",
    "Armazene os documentos disponíveis no diretório `DocCol2` em um dicionário onde a chave é o nome do arquivo e o valor é a string contida no arquivo. O documento contendo a menor string é:\n",
    "\n",
    "a) gr7<br>\n",
    "<font color='red'> b) au1 </font><br>\n",
    "c) ch37 <br>\n",
    "d) au81\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documento com a menor string:  au1 com 4573 caracteres\n"
     ]
    }
   ],
   "source": [
    "folder = \"../DocCol2/*\" # aqui vc deve mudar para o caminho onde o diretório DocCol2 está\n",
    "files = glob.glob(folder)\n",
    "\n",
    "docs = {}\n",
    "larger_doc = ['',1e10]\n",
    "for fname in files:\n",
    "    with open(fname,'r') as f:\n",
    "        key = fname.split('/')[-1]\n",
    "        docs[key] = f.read() \n",
    "        sizes = len(docs[key])\n",
    "        if larger_doc[1] > sizes:\n",
    "            larger_doc[0] = key\n",
    "            larger_doc[1] = sizes\n",
    "              \n",
    "print('documento com a menor string: ',larger_doc[0],'com',larger_doc[1],'caracteres')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2)\n",
    "Crie um dicionário chamado `docsXwords` onde as chaves são os nomes dos arquivos e os valores correspondem a lista de palavras do documento correspondente. As palavras em cada uma das listas devem ser constituídas apenas por letras do alfabeto, estarem lexicamente normalizadas e contendo dois ou mais caracteres. Qual o documento com o maior número de palavras associadas no dicionário `docsXwords`:\n",
    "\n",
    "a) gr22 com 1701 palavras<br>\n",
    "b) ch30 com 1513 palavras<br>\n",
    "<font color='red'> c) au2 com 1678 palavras</font><br>\n",
    "d) au8 com 1525 palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('au2', 1678), ('ch30', 1525), ('au14', 1503), ('ch44', 1481), ('ch28', 1422)]\n"
     ]
    }
   ],
   "source": [
    "docsXwords = {}\n",
    "for key in docs.keys():\n",
    "    #strings = docs[key].split(' ')\n",
    "    words = nltk.word_tokenize(docs[key])\n",
    "    words = [w.lower() for w in words if w.isalpha() and len(w) != 1]\n",
    "    words = [PorterStemmer().stem(w) for w in words]\n",
    "    docsXwords[key] = words\n",
    "    \n",
    "d={}\n",
    "for key,value in docsXwords.items():\n",
    "    d[key] = len(value)\n",
    "    \n",
    "dsorted = sorted(d.items(), key=lambda x: x[1], reverse=True)\n",
    "print(dsorted[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3)\n",
    "As listas de palavras do dicionário `docsXwords` possuem palavras repetidas. Construa um dicionário chamado `corpus` onde a chave é uma palavra que aparece nas listas de `docsXwords` e os valores correspondem ao número de vezes que a palavra apareceu em `docsXwords`. Por exemplo, supondo que `docsXwords` seja:\n",
    "\n",
    "```python\n",
    "'ch3':['the', 'nicen', 'creed']\n",
    "'au14':['the', 'river', 'creed', 'but']\n",
    "'gr8':['river', 'the', 'nicen', 'creed']\n",
    "```\n",
    "o dicionário `corpus` será:\n",
    "```python\n",
    "'the':3\n",
    "'nicen':2\n",
    "'creed':3\n",
    "'river':2\n",
    "'but':1\n",
    "```\n",
    "Quantas palavras estão associadas ao valor 1 no dicionário `corpus`?\n",
    "\n",
    "a) 2103<br>\n",
    "b) 1867<br>\n",
    "<font color='red'> c) 2862 </font><br>\n",
    "d) 3001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de palavras associadas ao valor 1 no corpus: 2862\n"
     ]
    }
   ],
   "source": [
    "# unificando todas as palavras em uma única lista\n",
    "corpus = [palavras for sublista in list(docsXwords.values()) for palavras in sublista]\n",
    "\n",
    "corpus = dict(Counter(corpus))\n",
    "single_words = list(filter(lambda x: x[1] == 1,corpus.items()))\n",
    "print('Número de palavras associadas ao valor 1 no corpus:',len(single_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4)\n",
    "Qual o documento cuja lista de palavras associadas em `docsXwords` possui o **maior** número de \"stop words\"? Quantas \"stop words\" aparecem neste documento:\n",
    "\n",
    "<font color='red'> a) ch30 com 835 \"stop words\" </font><br>\n",
    "b) gr17 com 147 \"stop words\"<br>\n",
    "c) au2 com 717 \"stop words\"<br>\n",
    "d) gr17 com 637 \"stop words\"\n",
    "\n",
    "**Dica**: Crie um dicionário a partir de docsXwords onde a chave é o nome do documento e o valor é o número de stop words no documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ch21', 704), ('ch24', 708), ('au2', 717), ('ch44', 734), ('ch30', 835)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lgnonato/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# lista das stop words\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "d={}\n",
    "for key,value in docsXwords.items():\n",
    "    nantes = len(value)\n",
    "    ndepois = len([w for w in value if w not in stop_words]) \n",
    "    d[key] = nantes - ndepois  # número de stop words\n",
    "    \n",
    "dsorted = sorted(d.items(), key=lambda x: x[1], reverse=False)\n",
    "print(dsorted[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5) \n",
    "Construa uma matriz Documentos $\\times$ Palavras a partir do dicionário `docsXwords` para a coleção de documentos do diretório `DocCol2`. Qual coluna da matriz possui a menor soma de valores? Qual o valor da soma?\n",
    "\n",
    "a) 'au1' com soma 3451<br>\n",
    "b) 'ch31' com soma 1754 <br>\n",
    "<font color='red'> c) 'gr5' com soma  256</font><br>\n",
    "d) 'ch3' com soma 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ch9  ch38  ch31  ch7  ch36  ch37  ch1  ch30  ch6  ch39  ...  ch16  \\\n",
      "from     6.0   3.0   6.0  1.0   9.0   9.0  7.0  41.0  6.0   5.0  ...  10.0   \n",
      "kempmp   3.0   0.0   0.0  0.0   0.0   0.0  0.0   0.0  0.0   0.0  ...   0.0   \n",
      "petri    4.0   0.0   0.0  0.0   0.0   0.0  0.0   0.0  0.0   0.0  ...   0.0   \n",
      "pihko    5.0   0.0   0.0  0.0   0.0   0.0  0.0   0.0  0.0   0.0  ...   0.0   \n",
      "subject  2.0   1.0   1.0  1.0   1.0   1.0  3.0   1.0  1.0   2.0  ...   1.0   \n",
      "\n",
      "         ch11  ch43  ch44  ch10  ch28  ch17  ch21  ch19  ch26  \n",
      "from      1.0   5.0   5.0   3.0  10.0   7.0   6.0   5.0   5.0  \n",
      "kempmp    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0  \n",
      "petri     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  \n",
      "pihko     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0  \n",
      "subject   1.0   1.0   1.0   1.0   2.0   2.0   1.0   1.0   2.0  \n",
      "\n",
      "[5 rows x 91 columns]\n"
     ]
    }
   ],
   "source": [
    "df_dXp = pd.DataFrame(data=np.zeros((len(corpus.keys()),len(docsXwords.keys()))),\\\n",
    "                  columns=list(docsXwords.keys()),index=list(corpus.keys()))\n",
    "\n",
    "for key,value in docsXwords.items():\n",
    "    dtemp = dict(Counter(value))\n",
    "    df_dXp.loc[list(dtemp.keys()),key] = list(dtemp.values())\n",
    "    \n",
    "print(df_dXp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coluna com menor soma gr5 com valor 256.0\n"
     ]
    }
   ],
   "source": [
    "S = df_dXp.sum(axis=0)\n",
    "# S_sorted = S.sort_values(ascending=True)\n",
    "# S_sorted.head()\n",
    "print('coluna com menor soma',S.idxmin(),'com valor',S.min())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
